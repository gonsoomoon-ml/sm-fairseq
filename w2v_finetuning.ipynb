{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31efc7-0a6d-4aac-839e-943b5b1630ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTALL_REQUIRES = False \n",
    "PREFIX = 'fairseq-custom'\n",
    "SRC_DIR = 'fairseq'\n",
    "\n",
    "import sys\n",
    "import IPython\n",
    "\n",
    "if INSTALL_REQUIRES:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    #     !{sys.executable} -m pip install -U split-folders tqdm albumentations crc32c wget\n",
    "    !{sys.executable} -m pip install 'sagemaker[local]' --upgrade\n",
    "    !{sys.executable} -m pip install -U smdebug sagemaker-experiments\n",
    "    !{sys.executable} -m pip install -U sagemaker ipyplot jsonlines\n",
    "    # !/bin/bash ./local/local_change_setting.sh\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea15c5-b348-40e9-bfba-a1c563e232fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from time import strftime\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cc45d-5ce5-4f27-8b0d-022051409da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sess = boto3.Session()\n",
    "region = sess.region_name\n",
    "account = boto3.client(\"sts\").get_caller_identity().get(\"Account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8af1b-66c1-4214-bd29-f950cb161efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f8980-98a3-4070-a25c-288c79e5d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1280249-fd67-4fb3-ab07-c90f19b83028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name):\n",
    "    create_date = strftime(\"%m%d-%H%M-%s\")\n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65055a95-fa80-4abe-99d5-0e6c89a9cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8e4bd-a588-45c9-bd47-09fe6b9e8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_base_path = f's3://{bucket}/{PREFIX}'\n",
    "s3_code_path = f'{s3_base_path}/code'\n",
    "s3_output_path = f'{s3_base_path}/output'\n",
    "s3_checkpoint_path = f'{s3_base_path}/checkpoints'\n",
    "s3_data_path = f's3://{bucket}/datasets/LibriSpeech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74d256-deb1-4f71-85f3-c08e8995f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$s3_data_path\"\n",
    "\n",
    "if [ ! -d datasets ]; then\n",
    "    mkdir datasets\n",
    "    mkdir datasets/raw-100\n",
    "    mkdir datasets/train-100\n",
    "    touch datasets/train-100/dummy\n",
    "    wget -P datasets/raw-100 https://www.openslr.org/resources/12/dev-other.tar.gz -q\n",
    "    wget -P datasets/raw-100 https://www.openslr.org/resources/12/train-clean-100.tar.gz -q\n",
    "    \n",
    "    # mkdir datasets/raw-960\n",
    "    # mkdir datasets/train-960\n",
    "    # touch datasets/train-960/dummy\n",
    "    # wget -P datasets/raw-960 https://www.openslr.org/resources/12/dev-other.tar.gz -q\n",
    "    # wget -P datasets/raw-960 https://www.openslr.org/resources/12/train-clean-100.tar.gz -q\n",
    "    # wget -P datasets/raw-960 https://www.openslr.org/resources/12/train-clean-360.tar.gz -q\n",
    "    # wget -P datasets/raw-960 https://www.openslr.org/resources/12/train-other-500.tar.gz -q\n",
    "    \n",
    "    aws s3 sync datasets $1    \n",
    "else\n",
    "    echo \"dataset is already downloaded\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb659c-6e55-411d-b543-ba8591cf53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/fairseq.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168151d-a5a0-4a9b-a7da-2e566698277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {SRC_DIR}/train.sh\n",
    "\n",
    "echo \"--------------------------------------------------------\"\n",
    "echo \"step 1: check environment \"\n",
    "echo \"--------------------------------------------------------\"\n",
    "\n",
    "nvidia-smi\n",
    "df -h\n",
    "\n",
    "## Preprocessing\n",
    "echo \"\"\n",
    "echo \"--------------------------------------------------------\"\n",
    "echo \"step 2: install dependencies \"\n",
    "echo \"--------------------------------------------------------\"\n",
    "\n",
    "chmod 1777 /tmp \n",
    "apt-get update -y\n",
    "apt-get install -y --allow-downgrades --allow-change-held-packages --no-install-recommends libsndfile1\n",
    "apt-get install libsndfile1-dev\n",
    "\n",
    "pip install soundfile tensorboardX editdistance torchsummaryX\n",
    "pip install --editable ./\n",
    "# export PYTHONPATH=$(pwd):$PYTHONPATH\n",
    "\n",
    "echo \"\"\n",
    "echo \"--------------------------------------------------------\"\n",
    "echo \"stage 3: prepare train data and generate manifests\"\n",
    "echo \"--------------------------------------------------------\"\n",
    "\n",
    "bash prepare-100.sh\n",
    "\n",
    "echo \"\"\n",
    "echo \"--------------------------------------------------------\"\n",
    "echo \"stage 4: download pretrained model\"\n",
    "echo \"--------------------------------------------------------\"\n",
    "\n",
    "mkdir /opt/ml/input/data/pretrained_models\n",
    "\n",
    "## pretrained data2vec-base model\n",
    "#wget https://dl.fbaipublicfiles.com/fairseq/data2vec/audio_base_ls.pt -P /opt/ml/input/data/pretrained_models -q \n",
    "\n",
    "## pretrained hubert-base model\n",
    "#wget https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960.pt -P /opt/ml/input/data/pretrained_models -q \n",
    "\n",
    "# pretrained wav2vec-base model\n",
    "wget https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt -P /opt/ml/input/data/pretrained_models -q \n",
    "\n",
    "echo \"\"\n",
    "echo \"--------------------------------------------------------\"\n",
    "echo \"stage 5: start finetuning\"\n",
    "echo \"--------------------------------------------------------\"\n",
    "cd $SM_MODULE_DIR\n",
    "export HYDRA_FULL_ERROR=1 \n",
    "# re-launch when train is unexpectedly crashed.\n",
    "for i in {0..9}\n",
    "do\n",
    "    echo \"\"\n",
    "    echo \"hydra-train start\"\n",
    "    fairseq-hydra-train $@\n",
    "    rm /opt/ml/model/crash.pt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98428e0b-25b2-4d5e-87bd-9badc1f63d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {SRC_DIR}/prepare-100.sh\n",
    "\n",
    "if [ ${SM_CHANNEL_TRAIN+x} ] && [ -d $SM_CHANNEL_TRAIN/LibriSpeech ]; then\n",
    "    echo \"train data is already unzipped\"\n",
    "else\n",
    "    if [ ${SM_CHANNEL_RAW+x} ] && [ -d $SM_CHANNEL_RAW ]; then\n",
    "        echo \"unzipping raw data\"\n",
    "        tar -zxf $SM_CHANNEL_RAW/train-clean-100.tar.gz -C $SM_CHANNEL_TRAIN\n",
    "        tar -zxf $SM_CHANNEL_RAW/dev-other.tar.gz -C $SM_CHANNEL_TRAIN\n",
    "    else\n",
    "        echo \"training data error\"\n",
    "        exit 0\n",
    "    fi\n",
    "    \n",
    "    mkdir -p $SM_CHANNEL_TRAIN/LibriSpeech/manifests\n",
    "    cd /opt/ml/code/examples/wav2vec\n",
    "    \n",
    "    echo \"downloading wav2vec dict \"\n",
    "    wget https://dl.fbaipublicfiles.com/fairseq/wav2vec/dict.ltr.txt -P $SM_CHANNEL_TRAIN/LibriSpeech/manifests -q\n",
    "    \n",
    "    echo \"generating tsv, ltr, wrd file (train-100)\"\n",
    "    python wav2vec_manifest.py $SM_CHANNEL_TRAIN/LibriSpeech/train-clean-100 --dest $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --ext flac --valid-percent 0\n",
    "    mv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train.tsv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train-100.tsv \n",
    "    python libri_labels.py $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train-100.tsv --output-dir $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --output-name train-100\n",
    "\n",
    "    echo \"generating tsv, ltr, wrd file (dev-other)\"\n",
    "    python wav2vec_manifest.py $SM_CHANNEL_TRAIN/LibriSpeech/dev-other --dest $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --ext flac --valid-percent 0\n",
    "    mv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train.tsv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/dev-other.tsv \n",
    "    python libri_labels.py $SM_CHANNEL_TRAIN/LibriSpeech/manifests/dev-other.tsv --output-dir $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --output-name dev-other\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad6356-66db-497c-b8e5-f068cb21f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {SRC_DIR}/prepare-960.sh\n",
    "\n",
    "if [ ${SM_CHANNEL_TRAIN+x} ] && [ -d $SM_CHANNEL_TRAIN/LibriSpeech ]; then\n",
    "    echo \"train data is already unzipped\"\n",
    "else\n",
    "    if [ ${SM_CHANNEL_RAW+x} ] && [ -d $SM_CHANNEL_RAW ]; then\n",
    "        echo \"unzipping raw data\"\n",
    "        tar -zxf $SM_CHANNEL_RAW/train-clean-100.tar.gz -C $SM_CHANNEL_TRAIN\n",
    "        tar -zxf $SM_CHANNEL_RAW/train-clean-360.tar.gz -C $SM_CHANNEL_TRAIN\n",
    "        tar -zxf $SM_CHANNEL_RAW/train-other-500.tar.gz -C $SM_CHANNEL_TRAIN\n",
    "        tar -zxf $SM_CHANNEL_RAW/dev-other.tar.gz -C $SM_CHANNEL_TRAIN\n",
    "        mkdir $SM_CHANNEL_TRAIN/LibriSpeech/train-960\n",
    "        mv $SM_CHANNEL_TRAIN/LibriSpeech/train-clean-100 $SM_CHANNEL_TRAIN/LibriSpeech/train-960/\n",
    "        mv $SM_CHANNEL_TRAIN/LibriSpeech/train-clean-360 $SM_CHANNEL_TRAIN/LibriSpeech/train-960/\n",
    "        mv $SM_CHANNEL_TRAIN/LibriSpeech/train-other-500 $SM_CHANNEL_TRAIN/LibriSpeech/train-960/\n",
    "    else\n",
    "        echo \"training data error\"\n",
    "        exit 0\n",
    "    fi\n",
    "    \n",
    "    mkdir -p $SM_CHANNEL_TRAIN/LibriSpeech/manifests\n",
    "    cd /opt/ml/code/examples/wav2vec\n",
    "    \n",
    "    echo \"downloading wav2vec dict \"\n",
    "    wget https://dl.fbaipublicfiles.com/fairseq/wav2vec/dict.ltr.txt -P $SM_CHANNEL_TRAIN/LibriSpeech/manifests -q\n",
    "    \n",
    "    echo \"generating tsv, ltr, wrd file (train-960)\"\n",
    "    python wav2vec_manifest.py $SM_CHANNEL_TRAIN/LibriSpeech/train-960 --dest $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --ext flac --valid-percent 0\n",
    "    mv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train.tsv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train-960.tsv \n",
    "    python libri_labels.py $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train-960.tsv --output-dir $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --output-name train-960\n",
    "\n",
    "    echo \"generating tsv, ltr, wrd file (dev-other)\"\n",
    "    python wav2vec_manifest.py $SM_CHANNEL_TRAIN/LibriSpeech/dev-other --dest $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --ext flac --valid-percent 0\n",
    "    mv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/train.tsv $SM_CHANNEL_TRAIN/LibriSpeech/manifests/dev-other.tsv \n",
    "    python libri_labels.py $SM_CHANNEL_TRAIN/LibriSpeech/manifests/dev-other.tsv --output-dir $SM_CHANNEL_TRAIN/LibriSpeech/manifests/ --output-name dev-other\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81762802-88cc-448c-a033-5003ad891be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'fairseq-vanilla-w2v-exp1'\n",
    "# instance_type = 'ml.g5.12xlarge' \n",
    "instance_type = 'local_gpu'\n",
    "instance_count = 1\n",
    "do_spot_training = False\n",
    "max_wait = None\n",
    "max_run = 5*24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0b598-0b39-41a4-ac47-971cd9d30a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "source_dir = f'{Path.cwd()}/{SRC_DIR}'\n",
    "\n",
    "\n",
    "if instance_type in ['local_gpu', 'local']:\n",
    "    from sagemaker.local import LocalSession\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    s3_raw_data_path = f'file://{Path.cwd()}/datasets/raw-100'\n",
    "    s3_train_data_path = f'file://{Path.cwd()}/datasets/train-100'\n",
    "    s3_checkpoint_path = None\n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    s3_raw_data_path = f'{s3_data_path}/raw-100'\n",
    "    s3_train_data_path = f'{s3_data_path}/train-100'\n",
    "    s3_checkpoint_path = f's3://{bucket}/{SRC_DIR}/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39255c7-fa11-47d2-9793-ab1c6209bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[{'Name': 'train:loss', 'Regex': '\"train_loss\": \"([0-9\\\\.]+)'}, \n",
    "                    {'Name': 'valid:wer', 'Regex': '\"dev-other_raw_wer\": \"([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c268282-e351-4b80-8a76-aa2010b65327",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'config-dir': '/opt/ml/code/examples/wav2vec/config/finetuning',\n",
    "    'config-name': 'base_100h',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054becbf-2c2c-420c-a7bd-96dce460e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = None\n",
    "\n",
    "if do_spot_training:\n",
    "    max_wait = max_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4234e-5c9c-4a61-a31f-32423007cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.sh',\n",
    "    source_dir=source_dir,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.10',\n",
    "    py_version='py38',\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    code_location = s3_code_path,\n",
    "    output_path=s3_output_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_run=max_run,\n",
    "    use_spot_instances=do_spot_training,\n",
    "    max_wait=max_wait,\n",
    "    checkpoint_s3_uri=s3_checkpoint_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7bf6b-04b2-48a9-971a-0b1c4e3a3572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name)\n",
    "estimator.fit(\n",
    "    inputs={\n",
    "        'raw': s3_raw_data_path, \n",
    "        'train': s3_train_data_path\n",
    "    },\n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "      'TrialName': job_name,\n",
    "      'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae73e8-8176-4787-8859-20904118ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce520fb2-26ff-4a8e-8f2c-f1942f1d3ec1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
